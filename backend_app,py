from flask import Flask, request, send_file, jsonify
import cv2
import numpy as np
import tempfile
import os
from werkzeug.utils import secure_filename
from ultralytics import YOLO

app = Flask(__name__)
port = 5000  # local port

# ===============================
# 1. LOAD CUSTOM YOLO MODELS
# ===============================
model_vehicle = YOLO("best_vehicle_detection.pt")  # For vehicle detection
model_sign = YOLO("best.pt")                       # For traffic sign detection

# ===============================
# 2. LANE DETECTION FUNCTIONS
# ===============================
def preprocess_frame(frame):
    """ Convert frame to grayscale, apply Gaussian blur, and Canny edge detection. """
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blurred, 50, 150)
    return edges

def region_of_interest(edges):
    """ Define a trapezoidal region of interest to focus only on lanes. """
    height, width = edges.shape
    mask = np.zeros_like(edges)
    polygon = np.array([[ 
        (int(width * 0.1), height),
        (int(width * 0.9), height),
        (int(width * 0.65), int(height * 0.55)),
        (int(width * 0.35), int(height * 0.55))
    ]], np.int32)
    cv2.fillPoly(mask, polygon, 255)
    return cv2.bitwise_and(edges, mask)

def average_lines(frame, lines):
    """ Average multiple Hough lines to create smoother lane lines. """
    left_lines, right_lines = [], []
    right_slopes = []
    
    if lines is not None:
        for line in lines:
            x1, y1, x2, y2 = line[0]
            slope = (y2 - y1) / (x2 - x1 + 1e-6)  # Avoid division by zero
            if 0.3 < abs(slope) < 2:  # Filter out near-horizontal/vertical lines
                if slope < 0:
                    left_lines.append((x1, y1, x2, y2))
                else:
                    right_lines.append((x1, y1, x2, y2))
                    right_slopes.append(slope)

    if right_slopes and np.mean(right_slopes) < 0.4:
        right_lines = []

    left_lane = make_lane_line(left_lines, frame)
    right_lane = make_lane_line(right_lines, frame)
    return left_lane + right_lane

def make_lane_line(points, frame):
    """ Fit a single line for detected lane points using polyfit. """
    if len(points) > 0:
        x_coords, y_coords = [], []
        for x1, y1, x2, y2 in points:
            x_coords.extend([x1, x2])
            y_coords.extend([y1, y2])
        poly = np.polyfit(x_coords, y_coords, 1)  # y = mx + b
        y1, y2 = frame.shape[0], int(frame.shape[0] * 0.6)
        x1, x2 = int((y1 - poly[1]) / poly[0]), int((y2 - poly[1]) / poly[0])
        return [(x1, y1, x2, y2)]
    return []

def detect_lanes(frame):
    """ Detect and draw lane lines using Hough Transform filtering. """
    edges = preprocess_frame(frame)
    roi_edges = region_of_interest(edges)
    lines = cv2.HoughLinesP(roi_edges, 1, np.pi / 180, threshold=50,
                            minLineLength=40, maxLineGap=100)
    averaged_lines = average_lines(frame, lines)

    lane_image = np.zeros_like(frame)
    for (x1, y1, x2, y2) in averaged_lines:
        cv2.line(lane_image, (x1, y1), (x2, y2), (0, 255, 0), 5)

    return cv2.addWeighted(frame, 0.8, lane_image, 1, 1)

# ===============================
# 3. PROCESS VIDEO FUNCTION
# ===============================
def process_video(input_video):
    cap = cv2.VideoCapture(input_video)
    if not cap.isOpened():
        raise ValueError("Cannot open video")

    temp_video = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    out = cv2.VideoWriter(temp_video.name, fourcc, fps, (width, height))

    vehicle_threshold = 0.4
    sign_threshold = 0.4

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        lane_frame = detect_lanes(frame)
        vehicle_results = model_vehicle(frame)
        sign_results = model_sign(frame)
        processed_frame = lane_frame.copy()

        for result in vehicle_results:
            for box in result.boxes:
                conf = float(box.conf[0])
                if conf > vehicle_threshold:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    cls_id = int(box.cls[0])
                    label = result.names[cls_id]
                    cv2.rectangle(processed_frame, (x1, y1), (x2, y2), (0, 0, 255), 2)
                    cv2.putText(processed_frame, f"{label} {conf:.2f}", (x1, y1 - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

        for result in sign_results:
            for box in result.boxes:
                conf = float(box.conf[0])
                if conf > sign_threshold:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    cls_id = int(box.cls[0])
                    label = result.names[cls_id]
                    cv2.rectangle(processed_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
                    cv2.putText(processed_frame, f"{label} {conf:.2f}", (x1, y1 - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

        out.write(processed_frame)

    cap.release()
    out.release()
    return temp_video.name

# ===============================
# 4. FLASK ROUTE FOR VIDEO UPLOAD
# ===============================
@app.route('/detect-video/', methods=['POST'])
def detect_video():
    if 'file' not in request.files:
        return jsonify({"error": "No file uploaded"}), 400

    file = request.files['file']
    filename = secure_filename(file.filename)
    temp_input = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
    file.save(temp_input.name)

    try:
        processed_path = process_video(temp_input.name)
        response = send_file(processed_path, mimetype='video/mp4', as_attachment=True)

        @response.call_on_close
        def cleanup():
            try:
                os.remove(temp_input.name)
            except Exception as e:
                print(f"Error deleting temp input file: {e}")
            try:
                os.remove(processed_path)
            except Exception as e:
                print(f"Error deleting processed video file: {e}")

        return response

    except Exception as e:
        return jsonify({"error": str(e)}), 500

# ===============================
# 5. START THE FLASK SERVER
# ===============================
if __name__ == '__main__':
    app.run(port=port, host='0.0.0.0', debug=True)





# from flask import Flask, request, send_file, jsonify
# import cv2
# import numpy as np
# import tempfile
# import os
# from werkzeug.utils import secure_filename
# from ultralytics import YOLO

# app = Flask(__name__)
# port = 5000  # Local port

# # Load YOLO models
# model_vehicle = YOLO("best_vehicle_detection.pt")
# model_sign = YOLO("best.pt")

# # ===============================
# # LANE DETECTION FUNCTIONS
# # ===============================
# def preprocess_frame(frame):
#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
#     blurred = cv2.GaussianBlur(gray, (5, 5), 0)
#     edges = cv2.Canny(blurred, 50, 150)
#     return edges

# def region_of_interest(edges):
#     height, width = edges.shape
#     mask = np.zeros_like(edges)
#     polygon = np.array([[ 
#         (int(width * 0.1), height),
#         (int(width * 0.9), height),
#         (int(width * 0.65), int(height * 0.55)),
#         (int(width * 0.35), int(height * 0.55))
#     ]], np.int32)
#     cv2.fillPoly(mask, polygon, 255)
#     return cv2.bitwise_and(edges, mask)

# def average_lines(frame, lines):
#     left_lines, right_lines = [], []
#     right_slopes = []
    
#     if lines is not None:
#         for line in lines:
#             x1, y1, x2, y2 = line[0]
#             slope = (y2 - y1) / (x2 - x1 + 1e-6)
#             if 0.3 < abs(slope) < 2:
#                 if slope < 0:
#                     left_lines.append((x1, y1, x2, y2))
#                 else:
#                     right_lines.append((x1, y1, x2, y2))
#                     right_slopes.append(slope)
    
#     if right_slopes and np.mean(right_slopes) < 0.4:
#         right_lines = []

#     left_lane = make_lane_line(left_lines, frame)
#     right_lane = make_lane_line(right_lines, frame)
#     return left_lane + right_lane

# def make_lane_line(points, frame):
#     if len(points) > 0:
#         x_coords, y_coords = [], []
#         for x1, y1, x2, y2 in points:
#             x_coords.extend([x1, x2])
#             y_coords.extend([y1, y2])
#         poly = np.polyfit(x_coords, y_coords, 1)
#         y1, y2 = frame.shape[0], int(frame.shape[0] * 0.6)
#         x1, x2 = int((y1 - poly[1]) / poly[0]), int((y2 - poly[1]) / poly[0])
#         return [(x1, y1, x2, y2)]
#     return []

# def detect_lanes(frame):
#     edges = preprocess_frame(frame)
#     roi_edges = region_of_interest(edges)
#     lines = cv2.HoughLinesP(roi_edges, 1, np.pi / 180, threshold=50,
#                             minLineLength=40, maxLineGap=100)
#     averaged_lines = average_lines(frame, lines)

#     lane_image = np.zeros_like(frame)
#     for (x1, y1, x2, y2) in averaged_lines:
#         cv2.line(lane_image, (x1, y1), (x2, y2), (0, 255, 0), 5)

#     return cv2.addWeighted(frame, 0.8, lane_image, 1, 1)

# # ===============================
# # VIDEO PROCESSING FUNCTION
# # ===============================
# def process_video(input_video):
#     cap = cv2.VideoCapture(input_video)
#     if not cap.isOpened():
#         raise ValueError("Cannot open video")

#     temp_video = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
#     fourcc = cv2.VideoWriter_fourcc(*'mp4v')
#     fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
#     width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#     height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
#     out = cv2.VideoWriter(temp_video.name, fourcc, fps, (width, height))

#     vehicle_threshold = 0.4
#     sign_threshold = 0.4

#     while True:
#         ret, frame = cap.read()
#         if not ret:
#             break

#         lane_frame = detect_lanes(frame)
#         vehicle_results = model_vehicle(frame)
#         sign_results = model_sign(frame)
#         processed_frame = lane_frame.copy()

#         for result in vehicle_results:
#             for box in result.boxes:
#                 conf = float(box.conf[0])
#                 if conf > vehicle_threshold:
#                     x1, y1, x2, y2 = map(int, box.xyxy[0])
#                     cls_id = int(box.cls[0])
#                     label = result.names[cls_id]
#                     cv2.rectangle(processed_frame, (x1, y1), (x2, y2), (0, 0, 255), 2)
#                     cv2.putText(processed_frame, f"{label} {conf:.2f}", (x1, y1 - 10),
#                                 cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

#         for result in sign_results:
#             for box in result.boxes:
#                 conf = float(box.conf[0])
#                 if conf > sign_threshold:
#                     x1, y1, x2, y2 = map(int, box.xyxy[0])
#                     cls_id = int(box.cls[0])
#                     label = result.names[cls_id]
#                     cv2.rectangle(processed_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
#                     cv2.putText(processed_frame, f"{label} {conf:.2f}", (x1, y1 - 10),
#                                 cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

#         out.write(processed_frame)

#     cap.release()
#     out.release()
#     return temp_video.name

# # ===============================
# # FLASK ROUTE FOR VIDEO UPLOAD
# # ===============================
# @app.route('/detect-video/', methods=['POST'])
# def detect_video():
#     if 'file' not in request.files:
#         return jsonify({"error": "No file uploaded"}), 400

#     file = request.files['file']
#     filename = secure_filename(file.filename)
#     temp_input = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
#     file.save(temp_input.name)

#     try:
#         processed_path = process_video(temp_input.name)
#         response = send_file(processed_path, mimetype='video/mp4', as_attachment=True)
        
#         @response.call_on_close
#         def cleanup():
#             os.remove(temp_input.name)
#             os.remove(processed_path)

#         return response

#     except Exception as e:
#         return jsonify({"error": str(e)}), 500

# # Start the Flask server
# if __name__ == '__main__':
#     app.run(port=port, host='0.0.0.0', debug=True)



# from flask import Flask, request, send_file, jsonify
# import cv2
# import numpy as np
# import tempfile
# import os
# from werkzeug.utils import secure_filename
# from ultralytics import YOLO

# app = Flask(__name__)
# port = 5000  # Local port

# # ===============================
# # 1. LOAD CUSTOM YOLO MODELS
# # ===============================
# model_vehicle = YOLO("best_vehicle_detection.pt")
# model_sign = YOLO("best.pt")

# # ===============================
# # 2. LANE DETECTION FUNCTIONS
# # ===============================
# def preprocess_frame(frame):
#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
#     blurred = cv2.GaussianBlur(gray, (5, 5), 0)
#     edges = cv2.Canny(blurred, 50, 150)
#     return edges

# def region_of_interest(edges):
#     height, width = edges.shape
#     mask = np.zeros_like(edges)
#     polygon = np.array([[ 
#         (int(width * 0.1), height),
#         (int(width * 0.9), height),
#         (int(width * 0.65), int(height * 0.55)),
#         (int(width * 0.35), int(height * 0.55))
#     ]], np.int32)
#     cv2.fillPoly(mask, polygon, 255)
#     return cv2.bitwise_and(edges, mask)

# def detect_lanes(frame):
#     edges = preprocess_frame(frame)
#     roi_edges = region_of_interest(edges)
#     lines = cv2.HoughLinesP(roi_edges, 1, np.pi / 180, threshold=50,
#                             minLineLength=40, maxLineGap=100)
    
#     lane_image = np.zeros_like(frame)
#     if lines is not None:
#         for line in lines:
#             x1, y1, x2, y2 = line[0]
#             cv2.line(lane_image, (x1, y1), (x2, y2), (0, 255, 0), 5)

#     return cv2.addWeighted(frame, 0.8, lane_image, 1, 1)

# # ===============================
# # 3. PROCESS VIDEO FUNCTION
# # ===============================
# def process_video(input_video):
#     cap = cv2.VideoCapture(input_video)
#     if not cap.isOpened():
#         raise ValueError("Cannot open video")

#     temp_video = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
#     fourcc = cv2.VideoWriter_fourcc(*'mp4v')
#     fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
#     width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#     height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
#     out = cv2.VideoWriter(temp_video.name, fourcc, fps, (width, height))

#     vehicle_threshold = 0.2
#     sign_threshold = 0.2

#     while True:
#         ret, frame = cap.read()
#         if not ret:
#             break

#         frame = cv2.flip(frame, 0)  # Fix video orientation
#         lane_frame = detect_lanes(frame)
        
#         vehicle_results = model_vehicle(frame)
#         sign_results = model_sign(frame)
#         processed_frame = lane_frame.copy()

#         for result in vehicle_results:
#             for box in result.boxes:
#                 conf = float(box.conf[0])
#                 if conf > vehicle_threshold:
#                     x1, y1, x2, y2 = map(int, box.xyxy[0])
#                     cls_id = int(box.cls[0])
#                     label = result.names[cls_id]
#                     cv2.rectangle(processed_frame, (x1, y1), (x2, y2), (0, 0, 255), 2)
#                     cv2.putText(processed_frame, f"{label} {conf:.2f}", (x1, y1 - 10),
#                                 cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

#         for result in sign_results:
#             for box in result.boxes:
#                 conf = float(box.conf[0])
#                 if conf > sign_threshold:
#                     x1, y1, x2, y2 = map(int, box.xyxy[0])
#                     cls_id = int(box.cls[0])
#                     label = result.names[cls_id]
#                     cv2.rectangle(processed_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
#                     cv2.putText(processed_frame, f"{label} {conf:.2f}", (x1, y1 - 10),
#                                 cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

#         out.write(processed_frame)

#     cap.release()
#     out.release()
#     return temp_video.name

# # ===============================
# # 4. FLASK ROUTE FOR VIDEO UPLOAD
# # ===============================
# @app.route('/detect-video/', methods=['POST'])
# def detect_video():
#     if 'file' not in request.files:
#         return jsonify({"error": "No file uploaded"}), 400

#     file = request.files['file']
#     filename = secure_filename(file.filename)
#     temp_input = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
#     file.save(temp_input.name)

#     try:
#         processed_path = process_video(temp_input.name)
#         response = send_file(processed_path, mimetype='video/mp4', as_attachment=True)

#         @response.call_on_close
#         def cleanup():
#             os.remove(temp_input.name)
#             os.remove(processed_path)

#         return response
#     except Exception as e:
#         return jsonify({"error": str(e)}), 500

# # ===============================
# # 5. START THE FLASK SERVER
# # ===============================
# if __name__ == '__main__':
#     app.run(port=port, host='0.0.0.0', debug=True)
